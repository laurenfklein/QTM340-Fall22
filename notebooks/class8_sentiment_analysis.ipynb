{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ycC9Vm1d7t"
      },
      "source": [
        "## Getting started with NLP and Sentiment Analysis ##\n",
        "\n",
        "Thus far, we have learned to access APIs, scrape, parse, and clean text. We're ready for NLP.\n",
        "\n",
        "But what's NLP?\n",
        "\n",
        "Natural Language Processing (NLP) names a broad range of techniques that involve applying computational analytical methods to text. (\"Natural language\" in this context just means human language as opposed to a programming language, like Python). In this unit, we'll explore many popular NLP techniques, beginning with sentiment analysis. \n",
        "\n",
        "Sentiment analysis is a method of quantifying the \"sentiment,\" or emotional intensity, of words and phrases in a text. Some sentiment analysis tools, including the one we'll be working with today, also factor in the emotional weight of other features of language, such as punctuation marks or emojis. In general, sentiment analysis processes a unit of text (a sentence, a paragraph, a book, an email, a song, a tweet) and outputs scores or other classifications that indicate whether that unit of text conveys a positive or negative sentiment (according to the particular algorithm and dictionary employed). Some tools go as far as to quantify the *degree* of positivity or degree of negativity within a text. \n",
        "\n",
        "How might this be helpful? A researcher interested in attitudes toward a political event, for example, might use sentiment analysis to characterize how people describe that event on Twitter. Combined with geographic data, sentiment analysis can be used to make comparisons across regions. Combined with demographic data, sentiment analysis can be used to understand how different groups of people view any particular event (or issue, or individual). Sentiment analysis can be easily scaled up, which makes it possible to analyze hundreds of thousands or even millions of speech events.\n",
        "\n",
        "Like any computational tool, sentiment analysis has limitations that must be taken into account. We'll explore some of these limitations via our readings and in class. (If you want a deep/fun/nerdy dive into these limitations, see [The Data-Sitters Club: Katia and the Sentiment Snobs](https://datasittersclub.github.io/site/dsc11.html)). In any case, when wielding sentiment analysis critically, creatively, and appropriately, it can lead to interesting results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYn8vPlI1d7v"
      },
      "source": [
        "### NLTK and VADER ###\n",
        "\n",
        "You will be using a few tools from Python's [NLTK](https://www.nltk.org/) (short for Natural Language Toolkit) to generate sentiment scores for the corpus that we created in Unit 1: the lyrics of the candidate playlists that we scraped from Genius.com. After completing today's other Jupyter notebook, you should have those lyrics in a directory in your \"my-work\" folder on JupyterHub.\n",
        "\n",
        "NLTK is a collection of libraries and tools that help researchers apply computational methods to texts. It's been in development since 2001--almost as old as you (or older)!--and it's used widely in the field of NLP. The tools included in NLTK range from methods of breaking up text into smaller pieces, to identifying whether a word belongs in a given language, to providing sample corpora (that's the plural of corpus) that researchers can use for training and development purposes. We'll be using NLTK a lot in the coming weeks. As with the previous unit, I'll introduce you to its features as we require them for our specific goals.   \n",
        "\n",
        "Today, we will be using one NLTK tool: [VADER](https://github.com/cjhutto/vaderSentiment) (short for Valence Aware Dictionary and sEntiment Reasoner), which generates positive, negative, and neutral sentiment scores for textual input.\n",
        "\n",
        "VADER has a lot of advantages over traditional methods of sentiment analysis, including:\n",
        "* It works well on social media text, yet readily generalizes to multiple domains;\n",
        "* It doesn’t require training data but is constructed from a generalizable, valence-based, human-curated gold standard sentiment lexicon;\n",
        "* It is fast enough to be used online with streaming data, and;\n",
        "* It does not severely suffer from a speed-performance tradeoff.\n",
        "\n",
        "The source of the above is an easy-to-read paper published by the creaters of VADER library, one of whom use to be my colleague at Georgia Tech. You can read it [here](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7F3gaEm1d7w"
      },
      "source": [
        "### Sentiment Lexicons, Sentiment Intensity, and Context-Awareness ###\n",
        "\n",
        "Traditionally, sentiment analysis worked by comparing text to a list of lexical features (i.e. words) that were determined by people to be either positive or negative. These are known as *sentiment lexicons.* (It's possible to create lexicons for other types of language as well; we'll talk about this more in the coming few days, as well as in Unit 3, when we discuss modeling in more detail.) \n",
        "\n",
        "More recently, tools have improved upon the positive/negative binary by offering more fine-tuned distinctions between varying degrees of positivity and negativity. This is known as *sentiment intensity*, and VADER does this well. For example, VADER scores “comfort” as moderately positive and “euphoria” as extremely positive. \n",
        "\n",
        "VADER also attempts to capture and score textual features common in informal online text such as capitalizations, exclamation points, and emoticons, as shown in the table below:\n",
        "\n",
        "![VADER table](https://programminghistorian.org/images/sentiment-analysis/sentiment-analysis1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtfnjhF41d7x"
      },
      "source": [
        "### Caveat Emptor! ###\n",
        "\n",
        "Like any text analysis tool, VADER should be evaluated critically and in the context of the assumptions it makes about communication. VADER was developed to analyze English language microblogging and social media sites (especially Twitter). This context is more informal than, for instance, political speeches; and more contemporary than, for instance, Shakespeare. But VADER was also developed as a general purpose sentiment analyzer, and the authors’ initial study shows it compares favorably against tools that have been trained for specific domains, use specialized lexicons, or resource-heavy machine learning techniques. That said, sentiment analysis continues to struggle to capture complex sentiments like irony, sarcasm, and mockery, when the average reader would be able to make the distinction between the literal text and its intended meaning.\n",
        "\n",
        "A few more caveats: while VADER is a good general purpose tool for English language texts, VADER only provides partial native support for non-English texts (it detects emojis/capitalization/etc., but not word choice). The developers encourage users to use automatic translation to pre-process non-English texts and then input the results into VADER. There might be better tools for non-English language texts. \n",
        "\n",
        "### Some examples of hard-to-classify sentences ###\n",
        "\n",
        "“The premise of the film was great, but it could have been better.”\n",
        "\n",
        "* What words would you identify as being associated with either positive or negative sentiment?\n",
        "* Would you say that this sentence have a positive or negative seniment? \n",
        "* What are some reasons that this sentence might be tricky for a sentiment analysis tool?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAlluS0R1d7x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBojEnhQ1d7y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzl7UHj81d7y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWrCGy3Y1d7y"
      },
      "source": [
        "“The best I can say about the movie is that it was interesting.”\n",
        "\n",
        "* What words would you identify as being associated with either positive or negative sentiment?\n",
        "* Would you say that this sentence have a positive or negative seniment? \n",
        "* What are some reasons that this sentence might be tricky for a sentiment analysis tool?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJlEbive1d7y"
      },
      "source": [
        "### Enough Talk, Time for Action! ###\n",
        "\n",
        "To use VADER, we need to import the nltk library and download and install the VADER lexicon. You do it like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8Qevnjf1d7y"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZWzJmzp1d7z"
      },
      "source": [
        "In order to get a sense of what VADER can do, let’s calculate the sentiment scores for one of the songs we scraped from Genius.com.\n",
        "\n",
        "The main component of VADER is its SentimentIntensityAnalyzer, so let's import that too:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NRe_q6U1d7z"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6MtKtsf1d70"
      },
      "source": [
        "(You can ignore the warning, if you get it, about not having twython installed). \n",
        "\n",
        "Technically, SentimentIntensityAnalyzer is a class, which we will use to build our own sentiment analyzer object.\n",
        "\n",
        "To do so, we call SentimentIntensityAnalyzer() and assign the output - our brand-new sentiment analyzer - to a variable, which we will name ‘sid’."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjmDPy8X1d70"
      },
      "outputs": [],
      "source": [
        "sid = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj_DDLce1d70"
      },
      "source": [
        "By doing this we have given \"sid\" all of the features of the VADER sentiment analysis object. It has become our sentiment analysis tool, but by a shorter name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9zmoKNC1d70"
      },
      "source": [
        "The method associated with the VADER sentiment analysis object that we want to use is what's called ‘polarity scores.’\n",
        "\n",
        "Calling the `polarity_scores` method on sid with our lyrics (or any string) outputs a dictionary with negative, neutral, positive, and compound scores for the input text. \n",
        "\n",
        "Let's do a quick test of how this works with some Tweets from the current Georgia governor's race:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN15ixOu1d70"
      },
      "outputs": [],
      "source": [
        "# https://twitter.com/staceyabrams/status/1572632059272695823 -- most recent tweet by Stacey Abrams as of 9/21/22\n",
        "scores = sid.polarity_scores(\"\"\"In Georgia, our differences are our superpower. The \n",
        "Latino community is diverse — that means their \n",
        "experiences and priorities in our state are also diverse \n",
        "whether it be through accessible health care or small businesses\"\"\") # remember multiline string formatting!  \n",
        "\n",
        "for key in scores:\n",
        "    print(key + \": \" + str(scores[key]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQTOD_m48DcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4f4zXjIs8Dqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g_OuGhl98D6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7FpOHiB1d70"
      },
      "source": [
        "Amazing! We just performed our first text analysis! \n",
        "\n",
        "But how do we analyze the analysis?\n",
        "\n",
        "VADER collects and scores negative, neutral, and positive words and features (and accounts for factors like negation along the way). The “neg”, “neu”, and “pos” values describe the fraction of weighted scores that fall into each category. So in this case, this song contains 0% negative features, 91.2% netural featurs, and 8.8% features. \n",
        "\n",
        "But what does the \"compound\" score mean? Clearly, this is not just the sum of the other three. It's more accurately described as a holistic score of the sentiment of whatever text has been passed in. It ranges from -1 to 1, and if you're curious, [here is one detailed explanation of how it's calculated](https://stackoverflow.com/questions/40325980/how-is-the-vader-compound-polarity-score-calculated-in-python-nltk). \n",
        "\n",
        "Now that we (sort of) know what these scores mean, let's try a few more political tweets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWIyma681d71"
      },
      "outputs": [],
      "source": [
        "# https://twitter.com/GovKemp/status/1572637818614325254 -- most recent tweet by Brian Kemp as of 9/21/22\n",
        "scores = sid.polarity_scores(\"\"\"(1/3) Fentanyl overdose deaths in Georgia teens are up \n",
        "800%, according to @GaDPH's latest report. As these \n",
        "poisons continue to flood across the U.S. southern \n",
        "border, the consequences of President Biden’s \n",
        "inaction on border security are being felt nationwide.\"\"\") \n",
        "\n",
        "for key in scores:\n",
        "    print(key + \": \" + str(scores[key]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do these numbers mean?"
      ],
      "metadata": {
        "id": "2HybLVXdimOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xTC_tA_0ioNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujkhL6cpiodb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXMEo7c7iosN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaQxkEsR1d71"
      },
      "outputs": [],
      "source": [
        "# https://twitter.com/HerschelWalker/status/1572335168676831233 -- most recent tweet by Hershel Walker as of 9/21/22\n",
        "\n",
        "scores = sid.polarity_scores(\"\"\"Wonderful to be in Jonesboro today at Crane \n",
        "Hardware, a successful small business founded in 1972 \n",
        "that has served the Jonesboro community ever since. \n",
        "\n",
        "@ReverendWarnock has hurt our small businesses. I’m \n",
        "going to Washington to change that. #gapol #gasen\"\"\")\n",
        "\n",
        "for key in scores:\n",
        "    print(key + \": \" + str(scores[key]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6VErTLyIi-k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ouh8hbN7i-2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YA6pOcE3i_RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://twitter.com/ReverendWarnock/status/1572661444080013312 -- most recent tweet by Raphael Warnock as of 9/21/22\n",
        "\n",
        "scores = sid.polarity_scores(\"\"\"Do you remember \n",
        "The 21st night of September? \n",
        "Love was changin' the minds of pretenders \n",
        "While chasin' the clouds away 🎶 \n",
        "Happy @EarthWindFire Day!\"\"\")\n",
        "\n",
        "for key in scores:\n",
        "    print(key + \": \" + str(scores[key]))"
      ],
      "metadata": {
        "id": "picZXSTojH_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xOOxLDKejIlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QXN9ZyGTjI7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HzNcXdemjahb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AUoB8xX1d71"
      },
      "source": [
        "So this is (hopefully) starting to make sense. Now let's get our Beyoncé lyrics again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exkaNhox1d71"
      },
      "outputs": [],
      "source": [
        "# get the text of some song lyrics\n",
        "import requests \n",
        "\n",
        "resp = requests.get('https://raw.githubusercontent.com/laurenfklein/QTM340-Fall22/main/corpora/lyrics/Beyonce-break-my-soul-lyrics.html')\n",
        "html_str = resp.text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use BeautifulSoup to find the lyrics tags on the page\n",
        "from bs4 import BeautifulSoup\n",
        "document = BeautifulSoup(html_str, \"html.parser\")\n",
        "\n",
        "lyrics_divs = document.find(\"div\", attrs={\"data-lyrics-container\": \"true\"})\n",
        "\n",
        "# convert the contents of these tags into text, preserving linebreaks \n",
        "lyrics = lyrics_divs.get_text(separator='\\n')"
      ],
      "metadata": {
        "id": "74wF-ebNnsd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the [CHORUS] and [VERSE] annotation\n",
        "\n",
        "import re\n",
        "\n",
        "cleaner_lyrics = re.sub((\"\\[.*\\]\"), \"\", lyrics) # this does not get the few that cross newlines\n",
        "\n",
        "cleanest_lyrics = re.sub(\"^\\[.+\\]\", \"\", cleaner_lyrics, flags=re.S) # this flag tells re.sub to look across multiple lines \n",
        "\n",
        "print(cleanest_lyrics)"
      ],
      "metadata": {
        "id": "X5rPocHNn2_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One thing I forgot to tell you about in the last lab:**\n",
        "\n",
        "**This is how you save a file from Colab to Google Drive**"
      ],
      "metadata": {
        "id": "n0sqh2LNojty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is how you save a file from Colab to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/beyonce-lyrics.txt\", \"w\") as file:\n",
        "    file.writelines(cleanest_lyrics)"
      ],
      "metadata": {
        "id": "k1zhpN02ou_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and this is how you read a file from your Google Drive into Colab \n",
        "\n",
        "with open(\"/content/gdrive/My Drive/beyonce-lyrics.txt\", \"r\") as file: \n",
        "  breakmysoul = file.read()\n",
        "\n",
        "print(breakmysoul)\n",
        "\n"
      ],
      "metadata": {
        "id": "wUugvHGao4Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLtZoQKK11gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L5GLhyre112P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qGaZzAyQ12Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1IRFCTw1d72"
      },
      "source": [
        "And now let's see what its sentiment turns out to be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_3iXaTM1d72"
      },
      "outputs": [],
      "source": [
        "scores = sid.polarity_scores(lines)\n",
        "\n",
        "for key in scores:\n",
        "    print(key + \": \" + str(scores[key]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXM7ZXJM1d72"
      },
      "source": [
        "What do these nummbers tell us?\n",
        "\n",
        "Let's [listen to the song](https://www.youtube.com/watch?v=yjki-9Pthh0) and see if we agree. \n",
        "\n",
        "### A Quick Note on Thresholds ###\n",
        "\n",
        "It can be helpful to set a minimum threshold for positivity or negativity so that you can classify a string/doc/etc as either positive or negative. The official VADER documentation suggests a threshold of -0.5 and 0.5, meaning to be counted negative it should be below -0.5 and as positive above 0.5. \"Respect\" easily meets the threshold for positive sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDZX1ktJ1d73"
      },
      "source": [
        "To get a sense of how \"Break My Soul\" compares to another song, let's try \"As it Was\" by Harry Styles "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Um4plH51d73"
      },
      "outputs": [],
      "source": [
        "resp = requests.get('https://raw.githubusercontent.com/laurenfklein/QTM340-Fall22/main/corpora/lyrics/Harry-Styles-as-it-was.txt')\n",
        "asitwas = resp.text\n",
        "\n",
        "print(asitwas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6tBHsMo1d73"
      },
      "outputs": [],
      "source": [
        "scores2 = sid.polarity_scores(asitwas)\n",
        "\n",
        "for key in scores2:\n",
        "    print(key + \": \" + str(scores2[key]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x3QdBQX1d73"
      },
      "source": [
        "So, VADER sees \"As It Was\" as neutral-to-positive. Listen for yourself [here](https://www.youtube.com/watch?v=H5v3kku4y6Q). Do you agree?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNqM-moE1d74"
      },
      "source": [
        "### Determining Appropriate Scope ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN_14tX_1d74"
      },
      "source": [
        "There isn't much calibration, or pre-processing, required of sentiment analysis. But there is one important aspect of calibration to consider when employing sentiment analysis: the unit of the text being analyzed.\n",
        "\n",
        "In the case of song lyrics, for example, we might want to analyze the entire song as a single unit, or we might want to analyze each line. \n",
        "\n",
        "* What are some research questions for which you might want to look at the entire song as a whole?\n",
        "* What are some research questions for which you might want to look at each line at a time?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE8rA09S1d74"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrZwGSq91d74"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tdKgQsI1d74"
      },
      "source": [
        "Let's redo our sentiment analysis so that we look at each line of the song individually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELUaX-DN1d74"
      },
      "outputs": [],
      "source": [
        "# re-intialize VADER\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# then split our song lyrics into lines broken up by newlines \n",
        "styleslines = asitwas.split('\\n') # note handy built-in python string function! \n",
        "\n",
        "# let's take a look\n",
        "styleslines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f245wJyP1d74"
      },
      "outputs": [],
      "source": [
        "# We add the additional step of iterating through the list of lines and \n",
        "# calculating and printing polarity scores for each one.\n",
        "\n",
        "for line in styleslines:\n",
        "    scores = sid.polarity_scores(line)\n",
        "    print(\"Comp. score: \" + str(scores['compound']) + \" \" + line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH39GH1l1d75"
      },
      "source": [
        "Here you’ll note a much more detailed picture of the sentiment in the song. \n",
        "\n",
        "* What seems interesting?\n",
        "* Did you notice any errors?\n",
        "* What are some research questions we could ask of our song lyrics corpus with sentiment analysis?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tnE-HdX1d75"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Lauren F. Klein wrote version 1.0 of this notebook, based off [Sentiment Analysis for Exploratory Data Analysis](https://programminghistorian.org/en/lessons/sentiment-analysis) by Zöe Wilkinson Saldaña with additional info by [Parul Pandey](https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f). It was updated in 2020 by Dan Sinykin and again by Lauren Klein in 2021 and 2022.*\n",
        "\n"
      ],
      "metadata": {
        "id": "aENhSEQa5KFm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11yCMVDX5Kk_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}